{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":"import speech_recognition as sr\n    from os import path\n    import os.path\n    import operator\n    from os import system\n    from os import listdir\n    from os.path import isfile, join\n    import wave\n    import scipy as sc\n    import librosa\n    import IPython.display as ipd\n    import numpy as np\n    from PIL import Image\n    import matplotlib.pyplot as plt\n    import matplotlib\n    import numpy as np\n    %matplotlib inline\n    import math\n    import librosa as lb\n    import scipy\n    from sklearn.decomposition import PCA\n    import pandas as pd\n    from os import listdir\n    from os.path import isfile, join\n    import time\n    from itertools import product\n    import datetime\n    import sys"},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":"def transcribe(my_path,model):\n    wit_key = ''\n\n    AUDIO_FILE =  path.join(my_path)\n\n    # use the audio file as the audio source\n    r = sr.Recognizer()\n    with sr.AudioFile(my_path) as source:\n        audio = r.record(source)  # read the entire audio file\n\n    if(model == 'google'):\n        # Google\n        try:\n            return r.recognize_google(audio)\n        except sr.UnknownValueError:\n             print(\"Google: -_-\")\n            \n        except sr.RequestError as e:\n            print(\"Google error; {0}\".format(e))\n"},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":"fs, data = scipy.io.wavfile.read(r\"C:\\Users\\hamza\\OneDrive\\Desktop\\ResearchML\\venmo.wav\")\nelementsInBucket = 25\nn = int(len(data)/elementsInBucket)\n\n#Breaks array into buckets of elements\ndef createBuckets(arr, n):\n    length = len(arr)\n    return [ arr[i*length // n: (i+1)*length // n] \n             for i in range(n) ]\n\n#Load audio file\narr = np.copy(data)\n#Store split array into variable\nsplitArray = createBuckets(arr,n)\n\nl = list()\n\nfor x in splitArray[:n]:\n    #print(np.fliplr([x])[0])\n    l.extend(np.fliplr([x])[0])\n\ndata2 = np.asanyarray(l)\n\nscipy.io.wavfile.write(r\"C:\\Users\\hamza\\OneDrive\\Desktop\\ResearchML\\venmo_temp.wav\", fs, data2)\ntranscribe(r\"C:\\Users\\hamza\\OneDrive\\Desktop\\ResearchML\\venmo_temp.wav\", \"google\")"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}